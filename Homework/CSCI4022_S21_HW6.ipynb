{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI4022 Homework 6; More Graphs and some Recommendations\n",
    "\n",
    "## Due Friday, April 9 at 11:59 pm to Canvas\n",
    "\n",
    "#### Submit this file as a .ipynb with *all cells compiled and run* to the associated dropbox.\n",
    "\n",
    "***\n",
    "\n",
    "Your solutions to computational questions should include any specified Python code and results as well as written commentary on your conclusions.  Remember that you are encouraged to discuss the problems with your classmates, but **you must write all code and solutions on your own**.\n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- Any relevant data sets should be available on Canvas. To make life easier on the graders if they need to run your code, do not change the relative path names here. Instead, move the files around on your computer.\n",
    "- If you're not familiar with typesetting math directly into Markdown then by all means, do your work on paper first and then typeset it later.  Here is a [reference guide](https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference) linked on Canvas on writing math in Markdown. **All** of your written commentary, justifications and mathematical work should be in Markdown.  I also recommend the [wikibook](https://en.wikibooks.org/wiki/LaTeX) for LaTex.\n",
    "- Because you can technically evaluate notebook cells is a non-linear order, it's a good idea to do **Kernel $\\rightarrow$ Restart & Run All** as a check before submitting your solutions.  That way if we need to run your code you will know that it will work as expected. \n",
    "- It is **bad form** to make your reader interpret numerical output from your code.  If a question asks you to compute some value from the data you should show your code output **AND** write a summary of the results in Markdown directly below your code. \n",
    "- 45 points of this assignment are in problems.  The remaining 5 are for neatness, style, and overall exposition of both code and text.\n",
    "- This probably goes without saying, but... For any question that asks you to calculate something, you **must show all work and justify your answers to receive credit**. Sparse or nonexistent work will receive sparse or nonexistent credit. \n",
    "- There is *not a prescribed API* for these problems.  You may answer coding questions with whatever syntax or object typing you deem fit.  Your evaluation will primarily live in the clarity of how well you present your final results, so don't skip over any interpretations!  Your code should still be commented and readable to ensure you followed the given course algorithm.\n",
    "\n",
    "---\n",
    "\n",
    "**Shortcuts:**  [Problem 1](#p1) | [Problem 2](#p2) | [Problem 3](#p3) | \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'networkx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-597ee4a96e6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'networkx'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a/ id='p1'></a>\n",
    "[Back to top](#top)\n",
    "# Problem 1 (15 pts; Coding: PageRank)\n",
    "\n",
    "\n",
    "\n",
    "Consider the sparsely encoded link matrix in `EVA_Links`.  Each row is an (i, j) link tuple, where the row is included if company i is an owner of company j.  Each to/from integer ID corresponds to an index in the accompanying file `EVA_nodename`.  There is no node name or company indexed `0`, so you'll want to account for that.  There is no header, and the encoding is UTF-8.\n",
    "\n",
    "#### a) \n",
    "\n",
    "Run the PageRank algorithm on this graph to determine the most powerful corporate \"owners,\" so we'll interpret edges as pointing *to* the owning party.  Report the final PageRanks as an ordered ranking of the pages, printing the top 10 **companies**.  Include a teleportation probability of 15%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_M_Compact(links):\n",
    "    n = max(max(links[0]), max(links[1]))\n",
    "    d = get_d(links)\n",
    "    l = [[] for i in range(n)]\n",
    "    for i in range(len(links)):\n",
    "        in_node  = links.iloc[i, 0] - 1\n",
    "        out_node = links.iloc[i, 1] - 1\n",
    "        l[in_node] = [len(d[in_node])]\n",
    "        l[in_node].append(d[in_node])\n",
    "    return l\n",
    "\n",
    "\n",
    "def get_d(links):\n",
    "    d = {}\n",
    "    for i in range(len(links)):\n",
    "        in_node  = links.iloc[i, 0] - 1\n",
    "        out_node = links.iloc[i, 1] - 1\n",
    "        if in_node not in d.keys():\n",
    "            d[in_node] = [out_node]\n",
    "        else:\n",
    "            d[in_node].append(out_node)\n",
    "    return d\n",
    "\n",
    "def get_M(links):\n",
    "    n = max(max(links[0]), max(links[1]))\n",
    "    M = np.zeros((n,n))\n",
    "    d = get_d(links)\n",
    "    for i in range(len(links)):\n",
    "        in_node  = links.iloc[i, 0] - 1\n",
    "        out_node = links.iloc[i, 1] - 1\n",
    "        M[in_node, out_node] = 1 / d[in_node]\n",
    "    return M\n",
    "\n",
    "def PageRank(M_compact, teleport_prob=0.15, iters=10, print_RV=False):\n",
    "    beta = 1 - teleport_prob\n",
    "    n = len(M)\n",
    "\n",
    "    # initial rank vector guess\n",
    "    r_old = np.repeat(1/n, n)\n",
    "    r_new = np.repeat((1-beta)/n, n)\n",
    "\n",
    "    # power iteration for M1\n",
    "    for page in range(n):\n",
    "        if len(M_compact[page]) != 0:\n",
    "            for dest in M_compact[page][1]:\n",
    "                idx = dest\n",
    "                r_new[idx] += beta*r_old[page]/M_compact[page][0]\n",
    "        \n",
    "    original_indices = [b[0] for b in sorted(enumerate(r_new),key=lambda i:i[1],reverse=True)]\n",
    "    \n",
    "    if print_RV:\n",
    "        print(\"Rank vector for G1: \", np.round(sorted(r_new, reverse=True), 10))\n",
    "    return sorted(r_new, reverse=True), original_indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_csv('EVA_Links.csv', header=None)\n",
    "nodes = pd.read_csv('EVA_nodename.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "M_Compact = get_M_Compact(links)\n",
    "ranks, og = PageRank(M_Compact, print_RV=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_items = 10\n",
    "indices = [og[i] for i in range(num_items)]\n",
    "for i in range(num_items):\n",
    "    print('{}: {} {}'.format(i+1, nodes.iloc[indices[i]+1, 0], indices[i]+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) \n",
    "\n",
    "The top 10 pages should include some companies you've heard of, but may also include many you *haven't*.  For those top 10 PageRanks, scan through the edges linking either *to* or *from* those pages and comment on any patterns that seem important.\n",
    "\n",
    "Do these top few results pass a sanity check, in the context of what those companies do?  \n",
    "\n",
    "Do they pass a sanity check that may suppor the claim that \"PageRank returns the most important ownership structures?\"  Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------\n",
    "Source on data set:\n",
    "\n",
    " UF Sparse Matrix Collection, Tim Davis\n",
    " \n",
    " http://www.cise.ufl.edu/research/sparse/matrices/Pajek/EVA\n",
    " \n",
    " name: Pajek/EVA\n",
    "\n",
    " date: 2002\n",
    " \n",
    " author: K. Norlen, G. Lucas, M. Gebbie, J. Chuang\n",
    " \n",
    "ed: V. Batagelj\n",
    "\n",
    "-------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "<a/ id='p1'></a>\n",
    "[Back to top](#top)\n",
    "# Problem 2 (Practice: Graph Cuts; 20 pts) \n",
    "Suppose our graph is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual edge assignments\n",
    "edges=[[0,1],[0,2],[0,3],[1,2],[1,3],[2,3],\\\n",
    "      [4,5],[4,6],[5,6],\\\n",
    "      [7,8],[7,9],[7,10],[8,9],[8,10],[9,10],\\\n",
    "      [11,12],[11,13],[11,14],[11,15],[12,13],[13,14],[14,15],\\\n",
    "      [16,17],[16,18],[16,19],[17,19],[18,19],[17,18],\\\n",
    "      [1,16],[2,14],[3,5],[5,7],[6,7],[4,10],[10,13],[7,13],[7,14],[13,15],[11,16],[18,20]]\n",
    "#create a dictionary as option\n",
    "nodes = list(range(21))\n",
    "neighbors={key: [] for key in range(len(nodes))} \n",
    "for edge in edges:\n",
    "    neighbors[edge[0]].append(edge[1])\n",
    "    neighbors[edge[1]].append(edge[0])\n",
    "    \n",
    "#other useful variables\n",
    "nodes = list(range(21))\n",
    "N = len(nodes)\n",
    "\n",
    "#networkx to plot the graph\n",
    "G=nx.Graph()\n",
    "nodes=[i for i in range(21)]\n",
    "G.add_nodes_from(nodes)\n",
    "for i in range(len(edges)):\n",
    "    G.add_edge(edges[i][0],edges[i][1])\n",
    "\n",
    "#plot the graph\n",
    "np.random.seed(6) #graph plotting algorithm is random; this ensures same image each time\n",
    "pos = nx.spring_layout(G) #algorithm that tries to \"cluster\" node plot locations\n",
    "colors=[0,0,0,0,1,1,1,2,2,2,2,3,3,3,3,3,4,4,4,4,5] #manual \"family\" groupings\n",
    "labels=dict(zip(range(21),range(21))); #label 0-20\n",
    "nx.draw_networkx_nodes(G, pos, node_color=colors, cmap='Pastel1', node_size=500, alpha=.75); #node colors easy to see labels over\n",
    "nx.draw_networkx_edges(G, pos, width=1.0, alpha=0.8); #draw edges\n",
    "nx.draw_networkx_labels(G, pos, labels, font_size=16); #label vertices by index/number\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loosely speaking, the data is generated from 5 clusters, although 2 clusters overlap somewhat.\n",
    "\n",
    "### Part 1:\n",
    "Find the Fiedler vector for the graph.  Plot the sorted Fiedler vector.  Use the `edges` array defined above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Part 2: Partitions\n",
    "\n",
    "#### Part 2a:\n",
    "\n",
    "Partition the graph into 2 graphs using this vector.  Include a picture of the associated *cut* of the graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Part 2b:\n",
    "\n",
    "Partition the graph into 3 subgraphs using the Fiedler vector.  One natural way to do so is to partitition at the two largest 1-D **jumps** in the sorted vector instead of just one cut at $y=0$.  Include both associated *cuts* in another picture of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Part 2c:\n",
    "\n",
    "Partition the graph into 4 subgraphs using bipartitioning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Part 2d:\n",
    "\n",
    "Of the 3 partitions above, which do you think were most appropriate.  Why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a/ id='p3'></a>\n",
    "[Back to top](#top)\n",
    "# Problem 3 (10 pts; Theory: Network MLEs)\n",
    "\n",
    "Suppose graphs are generated by picking a probability $p$ and choosing each edge independently with probability $p$, as if our entire network were coming from a Community Affiliation Graph Model (AGM) with only *one*  universal community.\n",
    "\n",
    "What value of $\\hat{p}$ gives the maximum likelihood of seeing a specific graph with $n$ total nodes and $e$ total edges? What is the probability that your observed, specific graph is the one generated, if $p=\\hat{p}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
